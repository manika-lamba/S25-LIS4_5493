---
title: "Supporting Data Collection: Documenting and Describing Data"
subtitle: "LIS 4/5493: Data Stewardship"
author: 
  - Dr. Manika Lamba
format:
  revealjs: 
    slide-number: true
    chalkboard: 
      theme: whiteboard
      buttons: true
    preview-links: false
    controls: true
    progress: true
    show-notes: separate-page
    logo: images/ou.png
    css: styles.css
editor: 
  markdown: 
    wrap: 72
---

## Introduction

![](images/clipboard-180740851.png){fig-align="center" width="300"}

::: notes
In the last module, we reviewed ORGANIZING data from a user-centered
perspective; how to STRUCTURE data so that it can be used for the
research project but also re-used and re-purposed by others and in
future projects; and options for STORING data during the research cycle.

We will continue the more practical aspects of the data life cycle this
week. In Module 4.2, we will learn more about how to support research or
researchers as data stewards.

The first phase of the data life cycle after planning the project is to
COLLECT the data. As we learned in Module 4.1 data stewards support
researchers and research projects by providing guidance about how to
ORGANIZE, STRUCTURE, AND STORE the data of the project.

Data stewards provide support in DOCUMENTING and DESCRIBING data by
assisting researchers (or they may document and describe the data for
the researcher) to choose appropriate documentation options and tools
for documenting and describing the data.

I have broken out this process into DOCUMENTING and DESCRIBNG because
they are two distinct activities using different methods that should be
completed during the collection phase of the research life cycle. The
DataOne lecture and some of the readings refers to this process as
DESCRIBING data but we will address them separately. Documenting and
describing data can also take place over the entire life cycle of the
date.

In this lecture, you will learn the processes of DOCUMENTING and
DESCRIBING data, as well as best practices and common metadata schemes
being used by specific domains or disciplines. The DataOne lecture and
the readings will provide additional discussion and examples of the
importance of describing data with metadata and standardized metadata
schemes.
:::

## Documenting Data

![](images/clipboard-524827008.png){fig-align="center"}

::: notes
Documenting and describing data are critical steps in the data life
cycle. Without clear, concise, and well-structured documentation and
metadata data can become unusable or inaccessible to researchers and
others.

Documenting and describing data have many benefits such as:

-   Data are made accessible by the research team for current and future
    use, but also by others
-   Context and background information related to the who, what, where,
    how, why, etc. explain the data, how it was developed, file formats,
    files in the dataset, etc.
-   Provide detailed history of data cleaning, preparation, copies, use,
    etc. for funder purposes but also so others can use and re-purpose
    the data
-   Documentation is part of the responsible conduct of research
:::

## Options for Documenting Data {.smaller}

::: columns
::: {.column width="50%"}
`ReadMe Files`

-   Researcher determines what they wish to include

-   Written in a way that makes sense to researcher

-   Includes basics about who, what, where, when, why, and how

-   Can be at file, folder, project level
:::

::: {.column width="50%"}
`Data Dictionary`

-   Spreadsheet that describes the structure of the project

-   Defines the fields in project files such as databases or
    spreadsheets

-   Includes technical details such as type of value in fields (text,
    data, numeric), length of field, etc.

-   Can also serve as a glossary to terms used in project, fields, etc.
:::
:::

::: notes
If you ask researchers how to access and use their data in five years
they may answer that they are not sure they will be able to.

Documenting data is essential to providing continued access, sharing,
re-using, and depositing data. There are several options for DOCUMENTING
data such as ReadMe files, Data Dictionaries, code books, or keeping a
data log.

The two most common are `ReadMe files` and `Data Dictionaries`, though
some data are documenting using several options. This slide describes
the purposes of ReadMe files and Data Dictionaries.
:::

## ReadMe Files Should Contain {.smaller}

-   Who is creating the record (if there are multiple people, explain
    each person's role)
-   Who owns the data
-   What was done (by each person)
-   When was the work done, clearly stating month, date, and year (use a
    standard format)
-   Where it was done (use standard formats if necessary)
-   Why research was done
-   What project the research is related to
-   How research was done (including the methodology)
-   What materials were used (e.g., reagents, surveys)
-   Links to locations of any related data (e.g., if the file has
    processed data, where the raw data files are)

::: notes
Important elements of a ReadMe file are listed on this screen and are
also discussed in the Henderson chapter for this module. ReadMe files
describe and provide context about the data, such as who created the
data and who owns the data. The role of each researcher can also be
described.

ReadMe files may also explain when and where and why the research was
done and what outcomes resulted from the data and data analysis
(publications, other data sets, other projects, etc.). ReadMe files also
can provide information about the research project such as methodology
used, sampling, materials, etc. Links to other related data could also
be included.
:::

## ReadMe Files Should Contain (Cont.) {.smaller}

If appropriate the following could be added:

-   Coding conventions used, for example, characters used for missing
    data or null sets, categories, classifications, acronyms, and
    annotations
-   List of folders that relate to a project
-   Interpretations
-   What could be done next
-   Any other elements that will help the researchers use and re-use the
    data

::: notes
ReadMe files may also contain information about the coding used, the
fields in the spreadsheet and their meaning and structures, next steps,
and other elements the researchers deem important to document the data
and data sets.
:::

## Best Practices for ReadMe Files {.smaller}

-   **Create one readme file for each data file, whenever possible.**
    -   It is also appropriate to describe a “dataset” that has
        multiple, related, identically formatted files, or files that
        are logically grouped together for use
-   **Name the readme so that it is easily associated with the data
    file(s) it describes.**
-   **Write your readme document as a plain text file**
    -   To avoid proprietary formats such as MS Word. Format the readme
        document so it is easy to understand
-   **Format multiple readme files identically.**
    -   Present the information in the same order, using the same
        terminology.
-   **Use standardized date formats.**
    -   Suggested format: W3C/ISO 8601 date standard, which specifies
        the international standard notation
        of YYYYMMDD or YYYYMMDDThhmmss.
-   **Follow the domain conventions of your discipline for taxonomic,
    geospatial and geologic names and keywords.**
    -   Whenever possible, use terms from standardized taxonomies and
        vocabularies

::: notes
Best Practices for ReadMe files are listed on this slide. There may also
be discipline-specific best practices to follow so it is good to check
if any exist and are currently used before writing a ReadMe file.

Generally a ReadMe file:

1.  Create only one ReadMe file for each data file
2.  Name the ReadMe file so that it is easily associated with the data
    file(s)
3.  Write the ReadMe file as a plain text file, not in proprietary
    software
4.  Format the multiple ReadMe files identically, consistently
5.  Use standardized data formats
6.  Follow the domain conventions of your discipline or taxonomic,
    keyword conventions
:::

## Recommended Minimum Content for Data

![](images/clipboard-3692911800.png){fig-align="center"}

::: notes
This slide shows the minimum content to include in a ReadMe file:

1.  Introductory information
2.  Name/institution address/email
3.  Date of data collection
4.  Data created
5.  Dates the data was updated and nature of the updates
6.  Keywords used to describe the data
:::

## Recommended Minimum Content for Data (Cont.)

![](images/clipboard-563258044.png)

::: notes
Recommended minimum content continued:

7.  Methodology information
8.  Design or protocols used in data collection
9.  Data specific information such as full names and definitions for
    column headings, units of measure, definitions for codes or symbols
    used for missing data, special formats or abbreviations used
10. Sharing and access information such as license restrictions, links
    to publications, citation for data set, and funding sources
:::

## Data Dictionaries

-   Define the fields in project files such as databases or spreadsheets
-   Include technical details such as type of value in fields (text,
    date, numeric), length of field, etc.
-   Can also serve as a glossary to terms used in project, fields, etc.

::: notes
Now let’s talk about Data Dictionaries. Data dictionaries (DD) describe
the structure of the project files, such as databases or spreadsheets.
The DD defines the fields in the database or columns in a spreadsheet.

It includes technical details about the structure such as values allowed
in fields, lengths of fields, or other limitations in the field or
column. It can also serve as a glossary for terms using in the project
files’ fields and columns. Methods to address missing values or other
common data issues may also be described, as may dates the file was
changed (edited, added to, copied, cleaned, etc.)
:::

## Data Dictionary: Example

![](images/clipboard-2070343642.png){fig-align="center"}

::: footer
<https://data.nal.usda.gov/data-dictionary-examples>
:::

::: notes
This slide shows an example of a data dictionary. There are many
examples online but this one is to a project at the USDA. Try to find
some other examples and compare what the researcher/data steward decided
to include.
:::

## Describing Data

-   Metadata = structured data about data
-   It is important to make a clear distinction between data and
    metadata
-   Data is what is gathered or generated as part of research
-   Metadata describes the data or data set(s) and makes it
    -   `F`indable
    -   `A`ccessible
    -   `I`nteroperable
    -   `R`e-useable

::: notes
Now let’s talk about DESCRIBING data.

Data are described by assigning metadata to the data file(s). Metadata
is defined as “structured data about data.” It is important to make a
clear distinction between “data” and “metadata” though some authors do
not. Data is what is gathered or generated over the course of the
research project. Metadata describes the data by using a structured
metadata scheme (or field structure in database terms).

There are many metadata schemes used in libraries, archives,
repositories, intranets, databases, etc. We will review a few in on the
next slide. Metadata is used in libraries for many purposes. When you
search for a book in the library OPAC or online discovery system you are
searching the metadata (or catalog records) that describe the book, not
the text or content of the book.

Metadata makes the data FAIR!!
:::

## Types of Metadata {.smaller}

1.  `Administrative:` related to the use, management, and encoding
    processes (technical, rights management, preservation)
2.  `Descriptive:` describes the work for purposes of discovery and
    identification (library catalog records, repositories)
3.  `Technical:` details the creation or storage processes or formats of
    the data
4.  `Structural:` indicates how compound objects are structured
5.  `Preservation:` describes provenance of data and its archival
    management

::: footer
National Information Standards Organization, 2004
:::

::: notes
There are several different types of metadata as described on this
slide. They each serve a specific purpose in describing the data, but
are all important to a full description. Not every scheme includes all
types of metadata.

The National Information Standards Organization (NISO) defines the types
of metadata as:

1.  **Administrative:** related to the use, management, and encoding
    processes (technical, rights management, preservation)
2.  **Descriptive:** describes the work for purposes of discovery and
    identification (library catalog records, repositories)
3.  **Technical:** details the creation or storage processes or formats
    of the data
4.  **Structural:** indicates how compound objects are structured
5.  **Preservation:** describes provenance of data and its archival
    management
:::

## Metadata Schemes

![](images/clipboard-2704601761.png){fig-align="center"}

::: notes
There are MANY metadata schemes, perhaps too many. There are very good
generic schemes that can be extended and used with any project, such as
the Dublin Core (DC) metadata scheme. DC has been in development and use
for about 20 years and is used by thousands of projects and digital
libraries, libraries around the world.

It is general, extensible, and interoperable with other schemes and can
easily work within many different infrastructures. The Henderson reading
for this module lists the general 15 elements that can be adapted and
added to by the project team. Other generic metadata schemes include
others used in libraries and archives such as MODS, METS, MADS (for name
authority data), or Encoded Archival Description (EAD) used by archives.

There are also discipline specific metadata schemes such as those listed
on the slide and in the readings this week. It is important to choose
the appropriate metadata scheme to describe the data so that it can be
deposited into a long term storage option such as a repository. If the
metadata scheme used to describe the data set and that of the repository
do not match, then interoperability may not be possible. We will talk
more about metadata compatibility issues in later modules.
:::

## Examples

![](images/ex.png){fig-align="center"}

::: notes
This is an example of the metadata describing the TextGrid Repository, a
digital humanities data repository. This screen shows the standards used
within the dataset. Note that the citation for the data set appears at
the bottom of the page, using the DataCite standard.
:::

## Standards Used with Metadata Schemes

![](images/clipboard-963274359.png){fig-align="center"}

::: notes
There are other standards that are used within the metadata schemes to
describe data. For example, in library catalog records the Resource
Description and Access (RDA) is a set of guidelines or instructions on
how to enter the metadata within the fields of a MARC record. (Grads,
you will learn more about MARC when you take LIS 5043.) 

Other
standards include those related to sources for the subject terminology
that is used to describe or represent subjects or topics of the data
set. A generic but comprehensive subject heading list that represents
the entire world of recorded knowledge is the Library of Congress
Subject Headings list (LCSH). This source can be used to describe
subjects in any project. 

There are also subject or discipline specific lists, or often referred to as thesauri or ontologies. I have listed a
few of them on the slide but there are many others. It is important that
you adhere to the standard subject heading list (also called a
controlled vocabulary or subject directory) for the discipline of the
data/research. 

In businesses they may use an ontology or taxonomy of
common terms used by employees of a company. You may also design an
ontology or taxonomy when developing a business-oriented project. 

Again, it is important to do some research of your own to determine the
best practice and metadata scheme being used by the discipline,
business, or institution. Failing to do so may affect retrieval of the
dataset within the repository or catalog. 

This concludes the 4.2
lecture. Be sure to also view the DataOne lecture on Metadata for this
module to learn more about documenting and describing the data set. The
readings I have selected also describe additional metadata schemes and
best practices for describing and documenting data.
:::
